---
title: "Assigment - Naive Bayes DIY"
author:
  - A. ten Napel - Author
  - A.Haijkers - Reviewer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```
---


```{r}
memory.limit(size=100000)
``` 


## Business Understanding
#### De data bestaat uit een set artikelen waar mee met behulp van Naive Base bepaald dient te worden of een artikel geclassificeerd moet worden als nieuws of als nepnieuws. 

## Data Understanding
```{r}
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s2y2122-Aronnpl/master/datasets/NB-fakenews.csv"
rawDF <- read_csv(url)
head(rawDF)
#RawDF<- read_csv(url)
#rawDF<-slice_head(RawDF,n=7500)
#although not necissary, I used the above code to make the sample size smaller when checking for errors, saving me a #lot of time where the computer would calculate only to return an error.
```

#### De data bestaat uit 5 variabelen en 20800 artikelen (rijen).

#### Om de data goed te interpreteren is het van belang om te begrijpen wat de verschillende kolommen inhouden.
##### id : unieke id voor een nieuwsartikel
##### titel : de titel van een nieuwsartikel
##### auteur : auteur van het nieuwsartikel
##### tekst : de tekst van het artikel; zou onvolledig kunnen zijn
##### label : een label dat het artikel als mogelijk onbetrouwbaar markeert
#####        1: onbetrouwbaar
#####        0: betrouwbaar

#### Om vooraf vast een inzicht te geven in de gegevens wordt eerst een verdeling gegeven. Zoals je kunt zien is dit vrij goed verdeeld.  
```{r}
#Tel.bezetting <- table(rawDF$type)
#we want to see the divide in trustworthy and untrustworthy news sources meaning we have to look at the label
Tel.bezetting <- table(rawDF$label)
Tel.bezetting
```

#### Aangezien de laatste kolom het label bevat zal deze gewijzigd moeten worden naar het type 'factor'


```{r}
#rawDF$type <- factor(rawDF$type)
#again, we want to turn the variable label into a factor
rawDF$label <- factor(rawDF$label)
head(rawDF, 5)
```

#### Het principe van Naive Base werkt op basis van gebruike woorden en de hoeveelheid hiervan. Om een eerste visuele indruk op te doen wordt er van zowel nieuws als nepniews een zogenoemde 'wordcloud' gemaakt. De tekst in het groen staat hierbij voor het 'nieuws' en de tekst in het oranje voor het 'nepnieuws'. 
```{r}
#nieuws <- rawDF %>% filter(label == "1")
#nepnieuws <- rawDF %>% filter(label == "0")
#it is important we select the right files, with 0 being the real news and 1 being untrustworthy
nieuws <- rawDF %>% filter(label == "0")
nepnieuws <- rawDF %>% filter(label == "1")

wordcloud(nieuws$text, max.words = 20, scale = c(4, 0.8), colors= c("green1","green2","green3","green"))
wordcloud(nepnieuws$text, max.words = 20, scale = c(4, 0.8), colors= c("orange1","orange2","orange3","orange"))
```
#### Uit deze 'workcloud valt ten eerste al op dat het woord 'president' in nieuws wel bij de top-20 hoort en bij het nepnieuws niet, hetzelfde geldt voor het woord 'years'. 


## Data Preparation
#### Nu we weten wat de data inhoud kunnen we de data gaan opschonen en bruikbaar maken voor analyse.
#### Eerst moeten we een corpus maken, dat verwijst naar een verzameling artikelen.

```{r}
#rawCorpus <- Corpus(VectorSource(rawDF$title))
#natrually we want to base our naive bays on the body of the text, not the title
rawCorpus <- Corpus(VectorSource(rawDF$text))
inspect(rawCorpus[1:2])
```

#### Aangezien deze artikelen veel inrelevante informatie bevatten welke de analyse ongewenst kan beinvloeden worden de hoofdletters omgezet naar kleine letters en worden de nummers, stopwoorden, leestekens en witruimtes eruit gefilterd. 

```{r}
cleanCorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers) %>%
  tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])
```
#### Laten we nu een matrix maken van de artikelen waarbij elke kolom een woord vertegenwoordigd en elke rij een artikel.
```{r}
cleanDNB <- cleanCorpus %>% DocumentTermMatrix 
#inspect(cleanCorpus)
inspect(cleanDNB)
```
#### Zoals in bovenstaande matrix te zien bevat deze 251838 terms, oftewel woorden. Dergelijke analyses kunnen hierdoor veel tijd kosten. Om snel resultaat te behalen wordt er voor gekozen om alleen woorden welke, in alle artikelen tezamen minimaal 10 maal voorkomen. Dit resulteerde in 42529 woorden welke overblijven. Echter was de vituele opslagcapaciteit van de desktop niet voldoende in een later stadium waardoor er voor gekozen is om alleen de woorden mee te nemen welke minimaal 30 keer voorkomen in de 20.800 artikelen. 

```{r}
#freqw <- cleanDNB %>% findFreqTerms(10)
#although technically not an error, since it would make the program unbearably slow/nonfunctional the number of terms #need to be reduced
freqw <- cleanDNB %>% findFreqTerms(30)
cleanDNBF <-  DocumentTermMatrix(cleanCorpus, list(dictionary = freqw))
inspect(cleanDNBF)
```

#### Nu de data voorbereid is zullen er trainings- en testsets gemaakt moeten worden om het model te kunnen testen. Met behulp van de createDataPartition()-functie kan gemakkelijk een verdeling worden gemaakt, in onderstaande is voor een verdeling gekozen van 70 tot 30. 
```{r}
set.seed(2202)
#trainIndex <- createDataPartition(rawDF$label, p = .30, 
#this would create a 30/70 split, not a 70/30
trainIndex <- createDataPartition(rawDF$label, p = .70, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```
```{r}
trainDF <- rawDF[trainIndex, ]
testDF <- rawDF[-trainIndex, ]
trainDTM <- cleanDNBF[trainIndex, ]
testDTM <- cleanDNBF[-trainIndex, ]
```

#### De laatste stap voordat we kunnen modelleren is het omzetten van getallen hoevaak een woord voorkomt naar een factor welke aangeeft of het woord uberhÃ¤upt voorkomt. Dit is benodigd vanwege de categorische  kenmerken.
```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])
```
## Modeling
#### Inmiddels is alle data goed genoeg om te kunnen modelleren. We maken hierbij eerst het model aan op basis van de traindata. 
```{r}
#nbayesModel <-  naiveBayes(trainDTM, trainDF$title, laplace = 1)
#again, the variable we are looking for it label, not title
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
```



#### Vervolgens kunnen we het model zelf testen. 
```{r}
predVec <- predict(nbayesModel, testDTM)
#confusionMatrix(predVec, testDF$label, positive = "1", dnn = c("Prediction", "True"))
#we are looking for reliable news which is indicated with a 0, not a 1
confusionMatrix(predVec, testDF$label, positive = "0", dnn = c("Prediction", "True"))
```
#### Zoals in bovenstaand resultaat te zien zijn de voorspellingen maar in 77,64% van de gevallen goed. Gezien de resultaten via Kaggle moeten er mogelijkheden zijn om dit te verbeteren. Een waarschijnlijkheid is dat het waarschijnlijk deels te verklaren is doordat er veel woorden zijn weggelaten. Echter koste het runnen van bovenstaande 3 chuncks al meerdere uren waardoor een verdere optimalisatie niet tijdig te realiseren is. 


## Evaluation and Deployment
You could improve it by doing as was said above and select words that occur ten times instead of 30. Although this would be more taxing on the computer running the program, it would give the computer a higher sample size of words to calculate with, giving us more accurate predictions on whether the article is reliable or not.